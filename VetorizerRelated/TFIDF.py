

'''  ç®€å•ä½¿ç”¨TF_IDF demo '''

# import numpy as np
# import pandas as pd
# from sklearn.feature_extraction.text import TfidfVectorizer
#
# # ğŸ”¹ 1. åˆ›å»ºæ–‡æœ¬æ•°æ®
# documents = [
#     "è‹¹æœ æ˜¯ ä¸€ç§ æ°´æœ",
#     "è‹¹æœ å’Œ é¦™è•‰ æ˜¯ æˆ‘ å–œæ¬¢ åƒ çš„ æ°´æœ",
#     "æˆ‘ è®¨åŒ åƒ é¦™è•‰ ä½†æ˜¯ å–œæ¬¢ åƒ è‹¹æœ",
#     "æ°´æœ é‡Œé¢ æˆ‘ æœ€ å–œæ¬¢ è‹¹æœ"
# ]
#
# # ğŸ”¹ 2. åˆå§‹åŒ– TF-IDF å‘é‡å™¨
# vectorizer = TfidfVectorizer()
#
# # ğŸ”¹ 3. è®¡ç®— TF-IDF çŸ©é˜µ
# tfidf_matrix = vectorizer.fit_transform(documents)
#
# # ğŸ”¹ 4. è·å–å•è¯åˆ—è¡¨
# feature_names = vectorizer.get_feature_names_out()
#
# # ğŸ”¹ 5. è½¬æ¢ä¸º DataFrame æ–¹ä¾¿æŸ¥çœ‹
# df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)
#
# # ğŸ”¹ 6. æ‰“å° TF-IDF ç»“æœ
# print(df_tfidf)


'''Word2Vec è¿›é˜¶ç‰ˆï¼Œæ˜ç¡®è¯­ä¹‰ç›¸ä¼¼åº¦'''
from gensim.models import Word2Vec

# ç¤ºä¾‹è¯­æ–™åº“
sentences = [
    ["è‹¹æœ", "æ˜¯", "ä¸€ç§", "æ°´æœ"],
    ["è‹¹æœ", "å’Œ", "é¦™è•‰", "æ˜¯", "æˆ‘", "å–œæ¬¢", "åƒ", "çš„", "æ°´æœ"],
    ["æˆ‘", "è®¨åŒ", "åƒ", "é¦™è•‰", "ä½†æ˜¯", "å–œæ¬¢", "åƒ", "è‹¹æœ"],
    ["æ°´æœ", "é‡Œé¢", "æˆ‘", "æœ€", "å–œæ¬¢", "è‹¹æœ"]
]

# è®­ç»ƒ Word2Vec æ¨¡å‹
model = Word2Vec(sentences, vector_size=50, window=5, min_count=1, workers=4)

# æŸ¥çœ‹ "è‹¹æœ" çš„è¯å‘é‡
print(model.wv["è‹¹æœ"])

# æ‰¾å‡ºæœ€ç›¸ä¼¼çš„è¯
print(model.wv.most_similar("è‹¹æœ"))